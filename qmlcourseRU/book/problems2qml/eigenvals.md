---
jupytext:
  formats: md:myst
  text_representation:
    extension: .md
    format_name: myst
kernelspec:
  display_name: Python 3
  language: python
  name: python3
---

(eigenvals)=

# Проблема собственных значений

## Введение

Мы с вами узнали, что задачи комбинаторной оптимизации и квантовой химии могут быть сведены к решению проблемы поиска минимального собственного значения большого эрмитова оператора -- гамильтониана. Для оптимизационных задач это [осуществляется](np2ising) при помощи сведения к _QUBO_-матрице и гамильтониану типа Изинга. А для электронных орьиталей из квантовой химии мы можем [применить](jordanwigner) преобразование Жордана-Вигнера и также перейти к спиновому гамильтониану.

Теперь переда нами встает вопрос, а как же искать основное состояние этого гамильтониана? В этой лекции мы рассматрим **классические** методы решения этой проблемы, то есть без квантовых компьютеров. Рассмотрение этих методов и их недостатков покажет то, зачем нам тут так нужен будет квантовый компьютер.

## О проблеме (повторение)

Эта тема обсуждалась во вводных лекциях по линейной алгебре, в [части про собственные вектора и собственные значения](../linalgblock/matrices.html#id9).

Итак, пусть у нас есть диагонализируемая матрица $A$ размерности $n \times n$, она же является линейным оператором $\hat{A}$. Из линейной алгебры мы знаем, что у этой матрицы есть $n$ таких чисел $e_i$ и таких векторов $\Psi_i$, что для них выполняется условие:

$$
A \Psi_i = e_i \Psi_i
$$

или в нотации Дирака, которая используется в области квантовых вычислений:

$$
\hat{A} \ket{\Psi_i} = e_i\ket{\Psi_i}
$$

Таким образом, собственные вектора -- это такие вектора, которые при применении оператора не меняют свое направление. Например, в примере ниже собственный вектор -- это ось симметрии оператора:

```{figure} /_static/problems2qml/eigenvals/Mona_Lisa.png
:width: 450px
:name: Mona_Lisa_Eigen
Синий вектор, в отличии от красного, при применении оператора не меняет направление так как является его собственным вектором.
```

## Итеративные алгоритмы

В целом, задача нахождения собственных значений является очень трудной с вычислительной точки зрения, особенно для больших матриц. Для матриц размера более, чем $3 \times 3$ в общем случае не существует алгоритма нахождения собственных значений и собственных векторов. Однако существует несколько итеративных алгоритмов. Мы рассмотрим лишь два из них, причем без особых деталей, так как эти алгоритмы, а также доказательство их сходимости являются достаточно сложными.

### Степенной метод

Один из самых простых для понимания алгоритмов, который, тем не менее находит интересные применения. Суть его в том, что мы берем некоторый случайный вектор $\ket{\Psi}$ и начинаем последовательно действовать на него оператором $\hat{A}$ (другими словами умножать, на нашу матрицу), при этом нормируя:

$$
\ket{\Psi_{i+1}} = \frac{\hat{A}\ket{\Psi_i}}{||\hat{A}||}
$$

И так мы повторяем до тех пор, пока изменение нашего вектора не будет меньше, чем некоторое заданное маленькое значение $\epsilon$. Когда мы достигли этого условия, это значит что мы нашли первый собственный вектор, который соответствует наибольшему собственному значению. В частном случае интересных нам эрмитовых операторов, можно так же последовательно находить все собственные вектора и собственные значения.

```{note}
На самом деле, наша сеть интернет является графом -- множеством связанных между собой вершин. А любой граф можно представить в виде большой-большой, но очень разреженной матрицы, каждый элемент которой это 1 если между соответствующими вершинами есть ребро и 0, если нет. Например, элемент $L_{ij}$ будет 1, если между вершинами $i$ и $j$ есть ребро. В 1998-м году, Ларри Пейдж и Сергей Брин нашли очень эффективный способ подсчета первого собственного вектор этой матрицы используя именно модификацию степенного метода. Этот алгоритм получил название `PageRank`, причем _Page_ это фамилия автора, а не отсылка к веб-страницам, как можно было бы подумать. Этот алгоритм лег в основу поисковика _Google_, который в дальнейшем вырос в транснациональную корпорацию!
```

### Итерация Арнольди

Это гораздо более сложный метод, который, однако, является одним из самых эффективных применительно к разреженным матрицам {cite}`arnoldi1951`. Объяснить его легко, к сожалению, не получится, так как алгоритм требует понимания Крыловских подпространств и других концептов из области линейной алгебры разреженных систем. Но нам достаточно лишь того, что этот алгоритм имеет очень эффективную реализацию -- [ARPACK](https://www.caam.rice.edu/software/ARPACK/), написанную в середине 90-х годов на языке `FORTRAN77`. Именно эта библиотека используется "под капотом" у `SciPy`, а также во многих других научных пакетах. Давайте посмотрим, как она работает.

Сгенерируем большую разреженную матрицу.

```{code-cell} ipython3
import numpy as np
from scipy import sparse

np.random.seed(42)
x = np.random.random(10000)
np.random.seed(42)
y = np.random.random(10000)
px = np.where(x > 0.2)
py = np.where(y > 0.2)
num_elements = max([px[0].shape[0], py[0].shape[0]])
spmat = sparse.coo_matrix(
    (
        (np.ones(num_elements),
        (px[0][:num_elements], py[0][:num_elements]))
    )
)
print(spmat.__repr__())
```

Матрица размера $10000 \times 10000$ это большая матрица и работать с ней в "плотном" (dense) представлении было бы очень трудно. Но `ARPACK` позволит нам найти минимальное собственное значение за доли секунд, используя разреженность матрицы:

```{code-cell} ipython3
from scipy.sparse import linalg as sl
max_eigval = sl.eigs(spmat, k=1, which="LR", return_eigenvectors=False)[0]
min_eigval = sl.eigs(spmat, k=1, which="SR", return_eigenvectors=False)[0]
print(f"Min E: {min_eigval}\nMax E: {max_eigval}")
```

Для тех кто забыл, какие параметры принимает функция `eigs` из `scipy.linalg.spare` напомним, что первый параметр это разреженная матрица, второй параметр (`k`) это то, сколько именно собственных значений мы хотим получить. Параметр `which` указывает, какие именно собственные значения мы хотим получить:

- `SM` -- _smallest magnitude_ -- наименьшие по модулю числа
- `LM` -- _largest magnitude_ -- наибольшие по модулю числа
- `SR` -- _smallers real_ -- числа с наименьшей действительной частью
- `LR` -- _largest real_ -- числа с наибольшей действительной частью
- `SI` -- _smallest image_ -- числа с наименьшей мнимой частью
- `LI` -- _largest image_ -- числа с наибольшей мнимой частью

Наконец, параметр `return_eigenvectors` указывает нам, хотим ли мы получить только собственные значения, или еще и собственные вектора.

Более подробна работа с `scipy.sparse`, а также с `scipy.sparse.linalg` разбирается в [вводном блоке по линейной алгебре](пока пусто).

```{note}
Не у всех матриц все собственные значения являются действительными, поэтому `ARPACK` по умолчанию считает нам комплексные значения, хотя в этом конкретном случае мы видим, что мнимая часть равна нулю.
```

### Алгоритм Ланкзоша

Итерация Ланкзоша (_англ._ Lanzos) {cite}`lanczos1950iteration` -- это модификация итерации Арнольди, которая работает с эрмитовыми матрицами и находит максимально широкое применение в том числе для квантовых гамильтонианов. Этот алгоритм по умолчанию включен в большинство математическиих пакетов, включая `ARPACK` и, соответственно, `SciPy`:

```{code-cell} ipython3
max_eigval = sl.eigsh(spmat, k=1, which="LM", return_eigenvectors=False)[0]
min_eigval = sl.eigsh(spmat, k=1, which="SM", return_eigenvectors=False)[0]
print(f"Min E: {min_eigval}\nMax E: {max_eigval}")
```

У этой процедуры из `ARPACK` немного другие варианты параметра `which`:


 - `LM` -- _largest magnitude_ -- наибольшие по модулю
 - `SM` -- _smallest magnitude_ -- наименьшие по модулю
 - `LA` -- _largest algebraic_ -- алгебраически наибольшие
 - `SA` -- _smallest algebraic_ -- алгебраически наименьшие

## Вариационные алгоритмы

В этом разделе мы поговорим о существующих алгоритмах решения задачи об основном состоянии уже в контексте квантовой механики. Хотя, как мы помним, задачи опимизации и квантойо физики [тесно связаны](../problems2qml/np2ising.html#id4). В каком-то смысле, вариационные алгоритмы, а в особенности, квантовый Монте-Карло и различные его модификации в чем-то сильно похожи на классический [алгоритм имитации отжига](../problemsblock/copt.html#id13).