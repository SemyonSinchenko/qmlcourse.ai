#+TITLE: Вариационные квантовые схемы
#+AUTHOR: Семен Синченко
#+LANGUAGE: ru
#+LATEX_HEADER: \usepackage{polyglossia}
#+LATEX_HEADER: \setmainlanguage[babelshorthands = true]{russian}
#+LATEX_HEADER: \setotherlanguage{english}
#+LATEX_HEADER: \setmainfont{Times New Roman}
#+LATEX_HEADER: \newfontfamily{\cyrillicfont}[Ligatures = TeX, Script=Cyrillic]{Times New Roman}
#+LATEX_HEADER: \newfontfamily{\cyrillicfontsf}[Ligatures = TeX, Script=Cyrillic]{Times New Roman}
#+LATEX_HEADER: \newfontfamily{\cyrillicfonttt}[Ligatures = TeX, Script=Cyrillic]{Times New Roman}
#+LATEX_HEADER: \usepackage{amsmath}
#+LATEX_HEADER: \usepackage{physics}
#+LATEX_HEADER: \usepackage{graphicx}
#+LATEX_HEADER: \usepackage{hyperref}
#+LATEX_HEADER: \usepackage{tikz}
#+HTML_HEAD_EXTRA: <link rel="stylesheet" type="text/css" href="https://tikzjax.com/v1/fonts.css">
#+HTML_HEAD_EXTRA: <script src="https://tikzjax.com/v1/tikzjax.js"></script>

* Описание лекции
На этой лекции мы впервые познакомимся с непосредственно квантовым машинным обучением. Теперь, вместо =NumPy= мы будем использовать =PennyLane=. Лекция включает следующие темы:
- В чем идея квантово-классического обучения?
- Что такое вариационное машинное обучение?
- Как устроена вариационная квановая схема?
- Как можно закодировать данные в вариационную схему?

* Введение
Далее, в течении всего курса, мы будем больше всего говорить о квантово-классическом машинном обучении, которое построено на базе вариационных квантовых схем. Именно этот тип комбинированного, квантово-классического машинного обучения является наиболее перспективным в NISQ-эру. Прежде, чем мы начнем, давайте заглянем немного вперед и посмотрим, как выглядит типичный цикл такого обучения.

#+begin_export html
<div align="center">
<script type="text/tikz">
\begin{tikzpicture}[node distance = 3.5cm]
    \node[align=center] (data) [rectangle, minimum width=2.5cm, minimum height=1cm, draw=black, fill=green!30] {$\mathbf{X}$};
    \node[align=center] (fencoding) [rectangle, rounded corners, minimum width=2.5cm, minimum height=1cm, draw=black, fill=red!30, below of=data] {$\hat{U(X)}$};
    \node[align=center] (params) [rectangle, rounded corners, minimum width=2.5cm, minimum height=1cm, draw=black, fill=red!30, below of=fencoding] {$\hat{U(\theta)}$};
    \node[align=center] (measure) [rectangle, rounded corners, minimum width=2.5cm, minimum height=1cm, draw=black, fill=red!30, below of=params] {$\hat{M}$};
    \node[align=center] (output) [rectangle, rounded corners, minimum width=2.5cm, minimum height=1cm, draw=black, fill=green!30, below of=measure] {$\hat{y}$};
    \node[align=center] (loss) [rectangle, rounded corners, minimum width=2.5cm, minimum height=1cm, draw=black, fill=green!30, right of=output] {$L$ $(y, \hat{y})$};
    \node[align=center] (grad) [rectangle, rounded corners, minimum width=2.5cm, minimum height=1cm, draw=black, fill=green!30, above of=loss] {$dL$ / $d\theta$};
    \node[align=center] (pupd) [rectangle, rounded corners, minimum width=3.5cm, minimum height=1cm, draw=black, fill=green!30, above of=grad] {$\theta$ = $\theta$ - $\gamma G$};
    \draw [thick,->,>=stealth] (data) -- (fencoding);
    \draw [thick,->,>=stealth] (fencoding) -- (params);
    \draw [thick,->,>=stealth] (params) -- (measure);
    \draw [thick,->,>=stealth] (measure) -- (output);
    \draw [thick,->,>=stealth] (output) -- (loss);
    \draw [thick,->,>=stealth] (loss) -- (grad);
    \draw [thick,->,>=stealth] (grad) -- (pupd);
    \draw [thick,->,>=stealth] (pupd) -- (params);
\end{tikzpicture}
</script>
</div>
#+end_export

#+begin_export latex
\begin{center}

\begin{tikzpicture}[node distance = 3.5cm]
    \node[align=center] (data) [rectangle, minimum width=2.5cm, minimum height=1cm, draw=black, fill=green!30] {$\mathbf{X}$};
    \node[align=center] (fencoding) [rectangle, rounded corners, minimum width=2.5cm, minimum height=1cm, draw=black, fill=red!30, below of=data] {$\hat{U(X)}$};
    \node[align=center] (params) [rectangle, rounded corners, minimum width=2.5cm, minimum height=1cm, draw=black, fill=red!30, below of=fencoding] {$\hat{U(\theta)}$};
    \node[align=center] (measure) [rectangle, rounded corners, minimum width=2.5cm, minimum height=1cm, draw=black, fill=red!30, below of=params] {$\hat{M}$};
    \node[align=center] (output) [rectangle, rounded corners, minimum width=2.5cm, minimum height=1cm, draw=black, fill=green!30, below of=measure] {$\hat{y}$};
    \node[align=center] (loss) [rectangle, rounded corners, minimum width=2.5cm, minimum height=1cm, draw=black, fill=green!30, right of=output] {$L(y, \hat{y})$};
    \node[align=center] (grad) [rectangle, rounded corners, minimum width=2.5cm, minimum height=1cm, draw=black, fill=green!30, above of=loss] {$\frac{dL}{d\theta}$};
    \node[align=center] (pupd) [rectangle, rounded corners, minimum width=2.5cm, minimum height=1cm, draw=black, fill=green!30, above of=grad] {$\theta = \theta - \gamma G$};
    \draw [thick,->,>=stealth] (data) -- (fencoding);
    \draw [thick,->,>=stealth] (fencoding) -- (params);
    \draw [thick,->,>=stealth] (params) -- (measure);
    \draw [thick,->,>=stealth] (measure) -- (output);
    \draw [thick,->,>=stealth] (output) -- (loss);
    \draw [thick,->,>=stealth] (loss) -- (grad);
    \draw [thick,->,>=stealth] (grad) -- (pupd);
    \draw [thick,->,>=stealth] (pupd) -- (params);
\end{tikzpicture}

\end{center}
#+end_export

Красным цветом на этой диаграмме помечены блоки, которые выполняются на квантовом устройстве, а зеленым то, что считается на обычном копмьютере. Квантовая часть, которая включает в себя операторы $\hat{U(X)}$ и $\hat{U(\theta}$, а также измерение наблюдаемой $\hat{M}$ как раз и называется вариационной квантовой схемой и именно ей мы посвятим сегодняшнее занятие.

Но сначала нам придется сделать шаг назад и обсудить в общих чертах идеи, которые лежат в основе квантово-классического обучения.

* Квантово-классическое обучение
Основная идея, которая ледит в основе квантово-классического обучения заключается в том, что в Noise Intermediate Scale Quantum (*NISQ*) эпоху у нас нет больших работающих квантовых компьютеров и нет квантовой памяти. Это сильно ограничивает нас в применении алгоритмов, которые дают нам гарантированное усорение над их классическими аналогами. Практически все, что нам остается, это "встраивать" квантовые схемы в классический цикл обучения.

В этом случае обычно мы разделяем классическую и квантовую части алгоритма. Мы выполняем предварительную обработку и подготовку данных на классическом компьютере, после чего "прогоняем" их через квантовую схему. Эта схема должна возвращать нам классические данные, а значит, включает в себя набор последовательно применяемых операторов и измерение. В этом случае, со стороны классического компьютера, такая схема будет выглядить как просто некий "черный ящик" или "оракул", с которым уже можно работать. Например, можно варьировать параметры схемы таким образом, чтобы она "обучалась" также, как "обучаются" нейронные сети или другие алгоритмы классического машинного обучения.

Давайте более детально посмотрим на квантовую схему, которая может быть использована в таком подходе.

* Вариационные квантовые схемы
В основе вариационных квантовых схем, или Variational Quantum Circuits (*VQC*) лежит достаточно простая идея. Давайте сделаем схему, которая включает в себя набор унитарных операторов и переводит классические данные $\mathbf{X}$ и параметры $\theta$ в квантовое состояние $\ket{\Psi}(\theta, \mathbf{X})$. А дальше, давайте /варьировать/ наше состояние $\ket{\Psi}$, меняя параметры $\theta$ так, чтобы при его измерении в каком-либо базисе мы получали нужный нам результат, например, результат классификации входных данных $\mathbf{X}$.

Давайте разберем это на простом примере.

** Аппроксимация матрицы Паули *X* оператором поворота
Как мы помним из предыдущих лекций, оператор $\hat{\mathbf{X}}$ работает как квантовый аналог оператора =NOT= -- он инвертирует значение кубита.

#+begin_src python
import pennylane as qml

dev = qml.device("default.qubit", 1)


@qml.qnode(dev)
def simple_x_gate():
    qml.PauliX(0)
    return qml.expval(qml.PauliZ(0))


simple_x_gate()
# tensor(-1., requires_grad=True)

simple_x_gate.draw()
# 0: ──X──┤ <Z>
#+end_src

С другой стороны, у нас есть оператор $\hat{RX}(\phi)$, который "вращает" состояние нашего кубита вокруг оси $\mathbf{X}$ на угол $\phi$. Давайте сделаем параметризованную схему с одним параметром:

#+begin_src python
@qml.qnode(dev)
def vqc(phi):
    qml.RX(phi, wires=[0])
    return qml.expval(qml.PauliZ(0))
#+end_src

Теперь давайте попробуем подобрать $\phi$ так, чтобы наша параметризованная схема работала точно также, как оператор $\hat{X}$:

#+begin_src python
vqc(0)
# tensor(1., requires_grad=True)

vqc(1)
# tensor(0.54030231, requires_grad=True)

vqc(2)
# tensor(-0.41614684, requires_grad=True)

vqc(3)
# tensor(-0.9899925, requires_grad=True)

vqc(3.14159265359)
# tensor(-1., requires_grad=True)
#+end_src

Мы получили, что нужный нам угол $\phi$ составляет ровно $\pi$. Это логично и мы могли это легко понять из простейший соображений линейной алгебры, либо даже взглянув на сферу Блоха. Но целью этого примера для нас было /почувствовать/ как работают VQC.
